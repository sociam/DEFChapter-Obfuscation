% PLEASE USE THIS FILE AS A TEMPLATE FOR THE PUBLICATION 
% Check file IOS-Book-Article.tex
%

\documentclass{IOS-Book-Article}     %[seceqn,secfloat,secthm]
%\usepackage{mathptmx}
%\usepackage[T1]{fontenc}
%\usepackage{times}%
%
%%%%%%%%%%% Put your definitions here
\usepackage{paralist}
\usepackage{graphicx}
\usepackage{color}
\usepackage{url}


%Make figures easier
\newcommand{\fig}[3][0.9]{
\begin{figure}[tp]
\begin{center}
\includegraphics[width=#1\textwidth]{figures/#2}
\caption{#3}
\label{fig:#2}
\end{center}
\end{figure}
}

\newcommand{\tbox}[3][red]{{
\color{#1}\noindent{
   \fbox{\scriptsize{ {\bf #2} \textsl{#3}}}
   \vspace{2pt}
}
}}


\definecolor{darkgreen}{rgb}{0,0.4,0}
\newcommand{\todo}[1]{\tbox{TODO:}{#1}}

%%%%%%%%%%% End of definitions
\begin{document}
\begin{frontmatter}          % The preamble begins here.
%
%\pretitle{}
\title{Social Palimpsests - clouding the lens of the personal panopticon}
\runningtitle{\ldots or ``Suck my tailpipe'' - how I learned to stop worrying
and toxify my exhaust data}
%\subtitle{}

% Two or more authors:
\author[A]{\fnms{Dave} \snm{Murray-Rust}},
\author[B]{\fnms{Max} \snm{van Kleek}}
\author[B]{\fnms{Laura} \snm{Dragan}}
\runningauthor{Murray-Rust et. al.}
\address[A]{Centre for Intelligent Systems and Applications,
Department of Informatics, University of Edinburgh}
\address[B]{Southampton}

\begin{abstract}
The use of personal data has incredible potential to benefit both society and
individuals, through increased understanding of behaviour, communication and
support for emerging forms of socialisation and connectedness. However, there
are risks associated with disclosing personal information, and present systems
show a systematic asymmetry between the subjects of the data and those who
control and manage the way that data is propagated and used. In this chapter, we
explore a set of techniques for ameliorating the tension between the 
the benefits of sharing, and a distrust of those with whom we share our data.
\end{abstract}

\begin{keyword}
Obfuscation; Data politics; Personal Data Stores; Social Machines; Pants-on-fire;
\end{keyword}

\end{frontmatter}

%%%%%%%%%%% The article body starts:

\section*{Introduction}

\subsection*{The rise of personal data and services reliant on it, and relation
so surveillance}

As we pass through the digitally augmented world that we collectively inhabit,
the set of actions with the potential to produce data grows year on year.
Portions of this outpouring are kept and stored as
\emph{capta}, from \emph{capere}: to keep \cite{dodge2005codes}. From
using an access card to unlock a door at the workplace, right down to tracking
individual footfalls, pervasive digital systems illuminate and annotate our
physical activity. Accreting around this body of physical observation is an
expanding sphere of mental observation and analysis. This can take the form of
active practises around recording mental states, such as journalling, but it can
also include computational inference, where frequency of posting on social
networks becomes an adjunct metric for connectedness, and search terms 
indicators of intent. As such, the modes of collection of this information can
range from explicit, user initiated submission of data, through consensual
background recording to invisible, asymmetric electronic surveillance.

The pervasiveness of computationally mediated interaction means that for much of
this data ``refusal is not a practical option, as data collection is an
inherent condition of many essential societal
transactions''\cite{brunton2011vernacular}. This leads us to introduce the term \emph{fiat data}---when an
organisation uses its position to demand (by fiat) the disclosure of certain
information in return for use of its services. The term comes from a loose
analogy with \emph{fiat money}: currencies whose value is derived from the
mandate of a government. 
\todo{this is gibberish, needs rewriting!}
Fiat money is, by definition
\emph{inconvertible}, and \emph{intrisically useless}, and hence must derive
its value from external forces, typically government decree, status as legal
tender or by being the required currency of taxation. While the conditions of
inconvertibility and uselessness are not necessarily applicable to personal
data, the mechanism of central authority decree is commonplace; if one wants to
interact socially on Facebook, one must pay the tax in personal data which they
demand. This can be contrasted with modern cryptocurrencies such as Bitcoin;
here, there is no central authority to backstop value and demand taxation.
Rather, the participants in the economy collectively decide what the units
of currency are worth; this would be a personal data economy in which
participants decided what and how they wanted to share.

Increasingly, in order to utilise services, we must provide our data to third
parties. This ranges from mobile phone numbers being required for Yahoo
accounts, to location data being shared with Foursquare or Grindr, to the NHS
adding personal health information to centralised databases. 


In some cases, this is a
necessary requirement for the service to be worthwhile, but in many cases it
represents an attempt by the organisation to create a monetizable product from
its users. One reaction would be be to reject the services which require data;
to \emph{opt-out}, but as Brunton and Nissenbaum put it:
\cite{brunton2011vernacular}

Gamification uses surveillance to effect behaviour change:
``1) that gamification is a form of surveillance; and 2) this surveillance is
pleasurable'' from Gaming the Quantified Self \cite{whitson2013gaming}, which
leads to  Albrechtslunds' ``participatory
surveillance''\cite{albechtslund2008online}:
\begin{quote}
Online social networking can also be empowering for the user, as the monitoring and 
registration facilitates new ways of constructing identity, meeting friends and colleagues 
as well as socializing with strangers. This changes the role of the user from passive to 
active, since surveillance in this context offers opportunities to take action, seek 
information and communicate. 
\end{quote} 


\subsection*{Sharing is a loss of control}

Sharing data, by definition, is the entrusting of other parties with
information; this necessarily involves relinquishing control over how it is
subsequently handled and disseminated. However, data is persistent, while people
and contexts change. A government may decide to share previously confidential
data, as in the case of the recent care.data fiasco in the UK; a company can be
bought and its assets acquired–the purchase of Moves by Facebook raised issues
around the terms and conditions of data handling companies; and even without
malice accidents can expose vast swathes of personal data, or court proceedings
may force private communications to become public - the Enron emails still
represent the largest publicly available corpus of private emails.  

Brad Templeton: ``Beware of time travelling robots from the future'' or ``Would
you have liked to be gay 40 years ago in a monitored society? Or an enemy of J.
Edgar Hoover with modern tools in his hands?'' \cite{templetonWatched}
Future tools will enable greater extraction and analysis of data after the fact;

David Lyon: leaky containers ``data move freely between different sectors of
society with the result that information from discrete contexts, e.g., private
life, work life and shopping, are being mixed rather than contained
separately.''

\subsection*{The case for lying and the importance of anonymity}

White lies can aid in social network growth: \cite{iniguez2014Deception}

Most, if not all, social interactions 
involve both strategic omissions and various kinds of lies and
non-truths to manage the myriad conflicting social demands placed upon us. 

Butler Lies: \cite{hancock2009butler}

Translucence: ``What we say and do with another person depends on who, and how
many, are watching.'' - \cite{erickson2000Translucence}

Contrast with Transparent society \cite{brin1999transparent}; power imbalance
between parties.

\subsection*{Multiple Identity}


A natural part of online life is the ability to tailor the persona we present to
different communities and contexts. An individual may want to disclose certain
things to their professional colleagues, while presenting differently to friends
and family or non-mainstream friend groups. 
\todo{Content creation on youtube}
\todo{Ben Dalton's thesis about Persona's throughout the agents}

\subsection*{Why doing it socially is difficult}

Sharing certain personal data is a barrier to anonymity and obfuscation; 
data which is rooted in physical fact provides multiple opportunities for
joining up otherwise separate databases. 
The
lie maintenance required to avoid discovery may be trivial (``sorry, I’m hungry,
have to go!'') but may become significantly more complicated as lies extend over
time, and become woven into the social fabric. The ability to compare
multiple accounts of history---especially once the time travelling
robots are involved---means that dissonance within the social
fabric is more obvious than weaknesses in a single thread.





\subsection{Personal Data Stores - allies on the intimacy battleground}

Personal data stores (PDS) represent a partial solution to issue of
presentation: having trusted, user controlled repositories for data enables a
more user-centric approach to management of capta---those data which we choose
to take and preserve. Bridges can then be built between personal data stores and
the rest of the world in order to support the connected, networked interactions
which users now expect. If these bridges simply share the data, even in a
controlled manner, nothing has been gained; hence the bridges become conduits
for manipulating truth and constructing falsehoods. As personal data stores
accumulate more real-time contextual data about the individual, as well as about
the individual’s social connections, PDSes can provide support for the often
stressful and mentally burdensome task of lie maintenance, for example: i)
identifying when a person's real activities or whereabouts contradict a lie, and
might be discovered; ii) identifying indirect social channels that could expose
a lie (e.g. through friends of friends); iii) suggesting appropriate lies to use
which are least likely to be detected; iv) suggesting individuals to lie to to
support lie maintenance (e.g. friends of the person being lied to)

\subsection{Why verification and provenance are better than sharing}

``Any model of privacy that focuses on the control of information will fail.''
``I call this practice “social steganography.” Only 
those who are in the know have the necessary information to look for and interpret the information 
provided.''
dana boyd \cite{boyd2012Networked}.

Sharing is a crude mechanism. Once data has been shared, the originator can no
longer exert control over it, and must rely on the behaviour of the recipient,
which as noted may fail to meet user expectations. Validation, however is a more
subtle tool: if a user’s personal dataset can be made sufficiently questionable
as to be useless on its own, then locus of control shifts to the user choosing
to validate parts of the dataset, which can be performed in a more nuanced,
contextualised manner. If a user is the final arbiter of trust, they can decide
to i) sign parts of their record, so that it is verified public fact; ii)
co-sign it with another entity, so either can verify it but not anyone else;
iii) verify it through an anonymous channel, so that the entity to whom they
provide verification cannot propagate the claim further. This verification can
be carried out entirely separately from the datastore itself, allowing for the
presentation of different datasets as valid  in different contexts, as well as
unorthodox methods such as using the Bitcoin blockchain to notarise datasets, so
that they can be verified in the future without revealing them as true at the
time.

\section{Review of current approaches and tools} 
\todo{Max to do some writing}

\begin{itemize}
  \item The revolution has started!
  \item TOR, anonymous remailers, burner phones, gotta change up, yo!
  \item Obfuscation symposium: \url{http://obfuscationsymposium.org/}
  \item Surveillance and Society: \url{http://library.queensu.ca/ojs/index.php/surveillance-and-society}
\end{itemize}

Theory of obfuscation:
Types of disinformation \cite{alexander2010Disinformation}:
\begin{description}
  \item[redaction] is hiding some or all of the information in a message
  \item[airbrushing] is changing some of the information. \emph{local crowd
  blending} means change it to a nearby message likely to be plausible.
  \emph{global crowd blending} means change it to a message in a dense part of
  the space.
  \item[curveball] add extra distracting information, push message into low
  density space
\end{description}

Some existing stuff and the things we can link it to later

\begin{itemize}
  \item TrackMeNot generates plausible google searches (Chaff)
  \item FaceCloak? Encrypts facebook data
  \item CacheCloak - sends a range of plausible future paths to location based
  services (Palimpsestification)
  \item Shopping card loyalty swaps (Account Sharing)
  \item DuckDuckGo - mixing up user searchers (Account Sharing, no cleverness)
  \item CVDazzle
\end{itemize}





\section{A selection of obfuscation strategies}
\todo{Laura to write descriptions and try redoing with maps}
Alexander's taxonomy \cite{alexander2010Disinformation} discusses several types
of disinformation which relate to modifying single messages. In contrast, due to
the pervasiveness of modern communications, we are concerned with modifying
message \emph{streams}, where a trace of multiple values must be considered.
Additionally, there is the possibility of interaction with others, whether it is
collusion to strengthen obfuscatory practices, or the addition---purposeful or
otherwise---of information which exposes the obfuscation.

It is problematic to consider the obfuscatory tactics here without a sense of
the scenario in which they are to be deployed. Our scenario in this paper is:
\begin{quote}
The user wishes to make use of services which expect location information; 
the location information provided is shared publicly and is almost
certainly stored indefinitely. At times, the user may want to draw on location
based information---such as restaurant recommendations or directions---and there
may be times when they with to verify that they were at a particular location.
\end{quote}
The service is hence \emph{semi-trusted}: there are some benefits which the user
wishes to accrue, but there are aspects of the service which makes the user
unwilling to entrust their complete life history to it.

\fig{Mediation}{Models of interaction with semitrusted services. a) Direct
transmission of information; b) computationally mediated transmission, where a
personal data store is enlisted to aid in obfuscatory processes.}

The standard model of interaction (Figure \ref{fig:Mediation}a) involves the
user submitting their data directly to the service; for our obfuscatory
techniques, we would like to enlist computational support (Figure
\ref{fig:Mediation}b). This typified, but not limited to mediation from a PDS
which acts on behalf of the user to modify the data which they provide.

\subsection{Single Player Strategies}

\fig[1.05]{SinglePlayerObfuscation}{Obfuscation strategies for the lone agent}

Figure \ref{fig:SinglePlayerObfuscation} lists a collection of possible
obfuscation strategies. In all cases, a fictitious one-dimensional ``location"
measurement is plotted against time, to give a sense of how an
individual's position in space changes. Figure \ref{SinglePlayerObfuscation}a is
the true baseline, with a curve indicating the continuous true position, and the dots
representing reports of this position to the location-aware service. For each
strategy we discuss: \begin{inparaenum}[\itshape i\upshape)]
\item what kind of alteration of baseline data is performed;
\item what the motivation and possible use cases are;
\item how some form of computational support aids in the deception;
\item how the strategy can be applied to other data
\item some of the systems which do this currently.
\end{inparaenum}

\subsubsection{Chaff}

World War II fighter planes would emit clouds of radar reflective
sheets---\emph{chaff}---which created multiple traces the screens of radar
operators, and hence disguised the true position of the aircraft. In a similar
manner, we can add in multiple location datapoints alongside the real ones. This
is the one of the few methods where the complete, accurate datastream is stored.
Hence the user can still access any benefits which rely on accurate information. However,
adding a multitude of randomised points to a service which expects a single
contiguous trace is both easily detectable, and may break functionality---a
run tracking application would be likely to give unreliable distance estimations
in the presence of chaff.

\subsubsection{Noise injection}

The most computationally simple form of obfuscation is the addition of noise to
the reports which are sent to the semi-trusted party. Here, the points which are
submitted deviate from the true values in a random manner. This allows the user
to conceal their exact location, while giving a broad indication of where they
are. Depending on the level of noise, this can allow the use of location
based services without revealing much about actual behaviour. For example, it
might reveal your location on the high street so you can arrange to meet
friends, without revealing which shops you were visiting. This is compatible
with services which expect coherent location data, and may be indistinguishable
from the inaccuracies of the location sensors. One downside is that the ``true''
location traces are not present in the record of the service.
\todo{examples?}

\subsubsection{Coarsened Granularity (or Quantisation)}

Rather than adding noise to the data being sent, it can instead be quantised to
a coarser granularity, akin to blurring, or zooming out on a map. Again, this is
a technique which may help to derive useful information from the service,
without revealing more than is necessary: using a service to find friends in the
same city should only require city level information to be shared. An example of
this can be found in Android's permission system, which has separate controls
for \verb|ACCESS_COARSE_LOCATION| versus \verb|ACCESS_FINE_LOCATION|; similarly,
posted letters may be signed with a city rather than a street address.

\subsubsection{Systematic Deviation}

In some cases, it may be possible to introduce systematic deviations into the
digital record. In order to this, the user needs to be able to define which
points to alter, and what to replace them with. One possibility would be
thematic replacement---``hide the times I went to the pub by saying I
was at a cafe''. It is likely that this will require some form of computational
support to i) identify targets for replacement as they occur and ii) find
suitable replacements. Using this technique, some, but not all of the true data
is stored; however derived information---such as beverage preferences in the
example above---can be wildly and purposefully distorted. The nature and fact of
the distortions may be hard to uncover, as no simulatneous traces or
strange movement patterns are produced. Depending on the domain, subtle
alterations may have large effects.
\todo{examples?}

\subsubsection{Pretend to be me}

With increasing computational support, it becomes possible to create a model of
the user which outputs plausible ``normal'' data. This can then be used to
replace periods of abnormal behaviour, or even replace normal behaviour with
statistically similar but untrue data. An early example is when neighbours (or
automatic switches) are employed to turn lights on and off in a home which has
been vacated for the holiday, disguising the true anomalous data of a dark,
empty house with the appearance of normal occupation. Similarly, one might avoid
making Facebook posts which indicate an absence, to avoid burglary. This kind of
deception can be difficult to achieve; however computational systems are
emerging which can aid users, for example Beyer's digital alibi system
\cite{beyer2014Alibi}.

\subsubsection{Virtual Holidays}
\begin{itemize}
  \item want to pretend that we're deviation from normal when we're not
  \item i.e. pretend we've gone to a conference when we haven't
  \item CompSupp: create a theme and help manage the deception
\end{itemize}

\subsection{Multiplayer Obfuscation}
\fig{MultiPlayerObfuscation}{Multiplayer obfuscaction strategies: i) artificial
co-location; ii) supporting information; iii) account sharing}

\subsubsection{Artificial co-location}
\begin{itemize}
  \item We can pretend that we're in the same place as our friends
  \item CompSupp: need to coordinate lies with friends
\end{itemize}

\subsubsection{Supporting Evidence}
\begin{itemize}
  \item We ask our friends for supporting evidence of our lie; could be like
  co-location, could be broader
\end{itemize}

\subsubsection{Account Sharing}
\begin{itemize}
  \item A group of people share accounts, with some way to decide which is
  used, e.g. accounts covering geographic areas
  \item Like swapping supermarket discount cards
  \item CompSupp: which account, when? discovery and sharing etc.
\end{itemize}

\subsubsection{Voltron!}

\section{Operationalisation - managing deception and its side effects}

\subsection{Going beyond location}

\subsection{PDSs to support obfusction}
\begin{itemize}
  \item create continuity
  \item act on your behalf
\end{itemize}

\subsection{Verification and provenance mechanisms}

\fig{Verification}{Example verification scenario. The user provides a set of
real data, plus \emph{chaff} to a location aware service. A third party then
requests verification of some of the points, which the user provides}

Previously, we said verification is better. Why is this?

\begin{itemize}
  \item Lets assume that we've made our public data completely unreliable so noone can
use it.
\item If someone wants to engage with it, they have to talk to us
\item we can claim a subset of the data - just what they say they need for the
purpose at hand
\item We then have a choice of how to respond:
\item No signing: if we simply send them a message saying ``these
points belong to me'', then they can use the data, but would not be able to
convince third parties of its validity.
\item sign with our private key; now, anyone can check that we have claimed that set of datapoints
\item sign with our private key and their public key: they can't prove the data
is ours without revealing their identity.
\end{itemize}

\subsubsection{Notarization}
\fig{Notarization}{Notarization of personal data. a) Datapoints and times are
hashed, and the values sent to a notary service, which provides a URL to verify
that i) the given data was supplied and ii) when it was supplied. Hashes are
used so that the data is not publicly shared. b) If the hash of the previous
submission is included, then sequences of consecutive points can be verified.}

Third party digital notarization services can be employed\footnote{e.g.
\url{http://virtual-notary.org/}, a free service hosted at Cornell University}.
These services take in some document or datum, and provide a certificate which
can be used to verify that that piece of data was provided at a certain time. For example, if someone wants to make a prediction
for the outcome of a football match, they could notarize that before the match,
and then subsequently prove that they had made the prediction beforehand. It is
generally not possible to prove that they only made a single prediction,
however, so this technique is most suitable when the range of possible things to notarize
is so large as to make notarizing the entire space infeasible.

With regard to personal data, we can notarize our true data stream as we produce
it. This means that we can prove that we had considered those points at the
time, and if we say we were in a particular place, there is a high chance we
were---however, it does not work in the complementary situtation as producing a
notarized point does not prove that we were not anywhere else.


Notarization does not necessitate revealing the data itself. For instance,
when submitting a location, a representation of the time and place could be
hashed, and this hash notarized (Figure \ref{fig:Notarization}a). Additionally,
points can be notarized in sequence, so that we can demonstrate contiguous sub-sequences 
of points as having been provided previously; by
hashing the current location with the previous location, we can link the points
together, to build up confidence in the notarized results (Figure
\ref{fig:Notarization}b).

\section{Conclusion}

\begin{itemize}
  \item Translation to things that aren't location data; generalisability; can't
  add chaff to our bank accounts (or can we?)
  \item Viability - how do services react when we fill them full of noise?
  Plausible versions of these techniques
  \item Ethics - is this OK?
  \item Obfuscation evolves in lockstep with systems to see through it; future
  people will be better at spotting constructed points.
  \item In the short term services will start to become more suspicious about
  the data that goes into them; start rejecting points which represent causality
  violations.
\end{itemize}

%%%%%%%%%%% The bibliography starts:
%\begin{thebibliography}{99}
%\bibitem{r1}
%\end{thebibliography}

\bibliographystyle{abbrv}
\bibliography{palimpsests}


\end{document}
